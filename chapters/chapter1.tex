\chapter{序論}

近年，ロボット技術は産業，物流，災害対応など多様な分野において，
実社会への展開が進んでいる.
これらの応用では，事前にすべての状況を想定して制御則を設計することが困難であり，
環境や状況に応じて柔軟に振る舞いを変化させる能力がロボットに求められる.
このような背景から，試行錯誤を通じて行動方策を獲得する学習的アプローチが，
ロボット制御の有力な手段として注目されてきた.

その代表的な枠組みが，環境との相互作用を通じて意思決定方策を学習する
強化学習（Reinforcement Learning; RL）である\cite{sutton2018reinforcement}.
近年では，深層ニューラルネットワークを関数近似器として用いることで，
高次元かつ非線形な制御問題に対しても高い性能を示すことが報告されている
\cite{hafner2020mastering,hafner2019dream,lee2020stochastic}.
RLは，環境モデルを事前に厳密に設計することなく方策を獲得できる点において，
複雑な実世界ロボット制御への応用可能性を有している.

一方で，実環境における試行錯誤には，
安全性やコストの観点から大きな制約が存在する.
そのため，限られたデータから効率的に学習可能な工夫が求められる.
この文脈において，環境の将来挙動を内部モデルとして学習し，
その予測に基づいて行動を計画する
モデルベース強化学習（Model-Based Reinforcement Learning; MBRL）
は，高いサンプル効率を実現する手法として位置付けられてきた
\cite{NIPS2014_c7c9344b}.

近年では，画像などの高次元観測を潜在空間に写像し，
その空間上でダイナミクス予測と行動計画を行うMBRL手法が数多く提案されている.
これにより，高次元観測を直接扱いながらも，
効率的かつ安定した行動計画が可能となり，
従来手法と比較して高いサンプル効率と制御性能を両立する枠組みが確立されつつある.

しかし，実環境への適用を考えた場合，
既存の多くのMBRL手法は依然として重要な課題に直面している.
MBRLは学習時に獲得された環境ダイナミクスに基づいて計画を行うため，
運用時にそのダイナミクスが異なる場合，
その影響が次状態予測誤差として顕在化し，
計画および制御性能の劣化を引き起こす可能性がある.

この問題が顕在化する代表的な例の一つが，
シミュレーション環境で学習した方策を実環境へ転移する際に生じる
Sim2Real Gap（シミュレーションと実環境の乖離）である.
シミュレーションと実環境の間には，
質量や摩擦係数，接触特性などの環境を決定する物理パラメータに差異が存在するため，
転移後に次状態予測の誤差が増大し，
計画の破綻や制御性能の低下を招くことがある.

さらに，学習と実行の環境が一致している場合であっても，
実環境では時間の経過とともにダイナミクスが変化する可能性がある.
ロボットの摩耗や経年劣化，個体差，部品交換などにより，
運用中に物理パラメータが変動し，
学習時とは異なるダイナミクスに直面することがある.
このような運用中の変化もまた，
MBRL手法の性能劣化を引き起こす要因となる.

このように，Sim2Real における転移時の乖離と，
実環境内で生じるダイナミクス変動は，
発生要因や時間的スケールは異なるものの，
いずれも物理パラメータの変動によって
学習時のダイナミクスモデルと実行時の環境ダイナミクスが乖離する点で共通している.
固定的なモデルに基づく計画は，
この乖離に対して本質的に脆弱であり，
結果として制御性能の低下を招きやすい.

以上の背景から，
実運用上起こりうる物理パラメータの変動に対しても
性能劣化を抑制可能なMBRL手法の構築が重要な課題である.
本研究では，MBRLの最先端アルゴリズムであるTD-MPC2\cite{hansen2023td}を基盤とし，
過去の挙動履歴から環境に固有な物理特性を推定し，
その情報をモデルの予測に反映させることで，
環境ダイナミクスの変化に適応する
モデルベース強化学習の枠組みを提案する.
本手法では，環境特性の同定と，
それに基づくダイナミクス予測とを概念的に分離して扱うことで，
物理特性の変動下においても
計画性能を維持することを目指す.

本研究の主な貢献を以下に示す.

\begin{itemize}
  \item \textbf{物理特性変動下における課題構造の整理}

  物理特性の変動がモデルベース強化学習の計画性能に与える影響を整理し，
  固定的な世界モデルに基づく手法の限界を明確化した.

  \item \textbf{環境特性同定に基づく適応的MBRL手法の提案}

  TD-MPC2を基盤とし，環境に固有な物理特性を明示的に同定し，
  その情報を世界モデルに反映させる適応的MBRL手法を提案した.

  \item \textbf{物理特性変動に対する有効性の検証}

  Pendulum-SwingupおよびWalker-Walkの制御タスクを用いて，
  物理特性変動下における性能を評価し，
  提案手法が非適応型ベースラインに対して有効であることを示した.
\end{itemize}

本論文の構成は以下のとおりである.
第2章では，モデルベース強化学習に関する基礎理論および関連研究を整理する.
第3章では，本研究の前提知識となるTD-MPC2の数理的定義を説明する.
第4章では，提案手法のシステム構成および学習・推論手順について述べる.
第5章では，評価に用いるタスク設定および実験条件を示し，
第6章で実験結果を報告する.
第7章では，得られた結果に関する考察を行い，
最後に第8章で本研究のまとめと今後の課題を述べる.
