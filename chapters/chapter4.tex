\chapter{提案手法}
\section{不確実環境における制御問題の再定式化}
\label{sec:problem_reformulation}

本節では，
第\ref{chap:preliminary}章で整理した TD-MPC2 の前提を踏まえ，
不確実な物理環境において生じる制御上の課題を明確化する．
その上で，
本研究が採用する基本的な設計方針について述べる．


\subsection{想定する環境不確実性と課題設定}
\label{subsec:uncertainty_setting}

本研究では，
ロボットの質量，摩擦係数，関節特性といった
\textbf{物理パラメータの不確実性}を主な対象とする．
これらのパラメータは，
環境や個体ごとに異なる一方で，
一つのエピソード内では時間的にほぼ一定であると仮定できる．

このような物理パラメータは，
単一時刻の観測から直接推定することは困難であり，
エージェントの行動に対する環境の応答として，
時間的に蓄積される挙動の違いの中に現れる．
したがって，
現在の観測のみに基づく意思決定では，
環境の特性を十分に捉えることができない．

一方で，
エージェントが過去の観測および行動の履歴を考慮することで，
環境固有の物理特性に関する情報を間接的に取得できる可能性がある．
この点は，
部分観測環境における制御問題として捉えることができる．


\subsection{既存 TD-MPC2 における暗黙的仮定とその限界}
\label{subsec:tdmpc2_limitation}

第\ref{chap:preliminary}章で述べたように，
TD-MPC2 は，
学習された世界モデル上での将来予測と，
モデル予測制御に基づく計画を統合した強力な制御手法である．
しかし，
TD-MPC2 では，
世界モデルが固定された環境ダイナミクスを表現していることが暗黙的に仮定されている．

この仮定の下では，
学習時に想定していない物理パラメータの変動が生じた場合，
世界モデルによる将来予測と実際の環境挙動との間に乖離が生じる．
この乖離は，
モデル予測制御におけるロールアウトを通じて累積し，
計画の信頼性を低下させる要因となる．

既存の TD-MPC2 では，
このような不確実性に対して，
暗黙的にロバストな潜在表現を学習することで対処していると解釈できる．
しかし，
この暗黙的な適応は，
どの物理的要因が性能劣化の原因であるかを明示的に示すものではなく，
制御性能の低下を事後的に分析・診断することが難しい．


\subsection{本研究の基本方針：不確実性の明示的同定}
\label{subsec:design_policy}

以上の背景を踏まえ，
本研究では，
環境の不確実性を単に吸収すべきノイズとして扱うのではなく，
\textbf{明示的に同定すべき対象}として捉える立場を取る．
すなわち，
環境の物理パラメータを推定し，
その推定結果を制御および計画に反映させることで，
将来予測の整合性を向上させることを目的とする．

ここで重要なのは，
推定対象を状態の一部として扱うのではなく，
制御に影響を与える\textbf{条件変数}として扱う点である．
物理パラメータは，
短時間で変化する状態とは異なり，
エピソード内でほぼ一定であるため，
履歴情報から推定し，
計画時に条件付けることが適している．

本研究の設計目標は，
単に平均的な性能を向上させることではなく，
不確実環境下における
(i) 計画の信頼性，
(ii) 推定結果の解釈性，
(iii) 性能劣化要因の診断可能性
を同時に向上させることである．
この方針に基づき，
次節以降では，
明示的な物理パラメータ推定器と，
それを用いた適応的なモデル予測制御の構成について述べる．


\section{提案手法のシステム構成}
\label{sec:system_overview}

本節では，
本研究で提案する明示的物理パラメータ同定に基づく制御手法の
システム全体構成について述べる．
提案手法は，
既存の TD-MPC2 を制御器の中核として保持しつつ，
相互作用履歴から環境の物理パラメータを推定するモジュールを追加し，
その推定結果を計画過程に条件として与える構成を採用する．


\subsection{全体アーキテクチャ}
\label{subsec:overall_architecture}

提案手法の全体アーキテクチャを図に示す．
本手法は，
大きく分けて
(i) 物理パラメータ推定モジュールと，
(ii) 条件付きモデル予測制御モジュール
の二つから構成される．

制御器の中核には，
第\ref{chap:preliminary}章で述べた TD-MPC2 をそのまま用いる．
すなわち，
観測 \(\mathbf{o}_t\) はエンコーダによって潜在状態 \(\mathbf{s}_t\) に写像され，
潜在空間上の世界モデルを用いたロールアウトと
モデル予測制御により行動が決定される．

これに対し，
提案手法では，
制御とは独立に，
過去の観測および行動の履歴を入力として
環境の物理パラメータを推定する推定モジュールを追加する．
この推定結果は，
制御器内部の潜在状態とは別の変数として保持され，
世界モデルおよび計画過程に条件として与えられる．

この構成により，
TD-MPC2 が本来持つ
高い計画性能および学習安定性を損なうことなく，
環境の物理的差異を明示的に反映した制御が可能となる．


\subsection{推定モジュールと制御モジュールの結合設計}
\label{subsec:module_coupling}

本研究では，
物理パラメータ推定モジュールと制御モジュールを
疎に結合した構成を採用する．
具体的には，
推定モジュールは制御器の外部に配置され，
推定結果は制御器に対して入力条件として与えられるのみであり，
制御器内部の潜在状態推定や価値学習とは直接的に干渉しない．

このような設計を採用した理由は二つある．
第一に，
物理パラメータは，
瞬時に変化する状態とは異なり，
エピソード内でほぼ一定であるため，
状態遷移モデルの一部として内部状態に統合する必要がない点である．
第二に，
推定器と制御器を強く結合した場合，
勾配の干渉や学習の不安定化が生じやすく，
既存の TD-MPC2 が持つ学習特性を損なう可能性がある．

提案手法では，
推定された物理パラメータを
制御に影響を与える条件変数として扱い，
世界モデルおよび計画アルゴリズムに明示的に与える．
これにより，
同一の潜在状態および行動であっても，
異なる物理パラメータ条件下では
異なる将来予測および計画結果が得られる．

このように，
推定モジュールと制御モジュールを役割分担に基づいて分離することで，
提案手法は
(i) 物理パラメータ推定の解釈性，
(ii) 制御性能の安定性，
(iii) 設計および実装の単純性
を同時に満たす構成となっている．


\section{明示的物理パラメータ推定器}
\label{sec:explicit_sysid}

本節では，
相互作用履歴から環境の物理パラメータを推定するために導入した，
明示的物理パラメータ推定器について述べる．
本研究では，
物理パラメータを時間的にほぼ不変な環境特性として捉え，
状態推定とは異なる推定問題として定式化する．


\subsection{相互作用履歴に基づく推定問題の定式化}
\label{subsec:sysid_formulation}

時刻 \(t\) における過去 \(K\) ステップ分の観測および行動の履歴を，
次のように定義する．

\begin{align}
\mathcal{H}_t
=
\{(\mathbf{o}_{t-K}, \mathbf{a}_{t-K}), \ldots, (\mathbf{o}_{t-1}, \mathbf{a}_{t-1})\}.
\end{align}

本研究では，
この履歴情報 \(\mathcal{H}_t\) に基づいて，
環境に固有な物理パラメータ
\(\mathbf{c}_{\mathrm{phys}} \in \mathbb{R}^d\)
を推定する問題を考える．
ここで，
\(\mathbf{c}_{\mathrm{phys}}\) は，
質量や摩擦係数など，
制御性能に大きな影響を与えるが，
単一時刻の観測からは直接得られない量を表す．

重要なのは，
\(\mathbf{c}_{\mathrm{phys}}\) が
短時間で変化する状態変数ではなく，
エピソード内ではほぼ一定であるという点である．
このため，
本研究では，
\(\mathbf{c}_{\mathrm{phys}}\) を
状態空間に含めて逐次推定するのではなく，
履歴全体から推定される条件変数として扱う．

この定式化により，
推定問題は次の写像として表現できる．

\begin{align}
\hat{\mathbf{c}}_{\mathrm{phys},t}
=
g_{\theta}(\mathcal{H}_t),
\end{align}

ここで，
\(g_{\theta}(\cdot)\) は
履歴から物理パラメータを出力する推定器を表す．


\subsection{GRU による履歴情報のエンコーディング}
\label{subsec:gru_encoding}

相互作用履歴 \(\mathcal{H}_t\) は時系列データであり，
物理パラメータに関する情報は，
行動に対する環境応答の違いとして時間的に現れる．
このような時系列依存性を捉えるため，
本研究では再帰型ニューラルネットワーク（RNN）の一種である
Gated Recurrent Unit (GRU) を用いて履歴をエンコードする．

GRU は，
入力系列を逐次的に処理し，
隠れ状態 \(\mathbf{h}_t\) に過去の情報を集約する．
本研究では，
各時刻の入力を
観測と行動の組 \((\mathbf{o}_{t}, \mathbf{a}_{t})\)
として GRU に与え，
最終的な隠れ状態を
履歴全体の要約表現として用いる．

GRU を採用した理由は，
LSTM と比較して構造が簡潔であり，
少ないパラメータ数で安定した学習が可能である点にある．


\subsection{物理パラメータ回帰モジュール}
\label{subsec:parameter_regression}

GRU により得られた隠れ状態 \(\mathbf{h}_t\) を入力として，
物理パラメータを回帰するモジュールを構成する．
具体的には，
\(\mathbf{h}_t\) を全結合層に入力し，
推定値 \(\hat{\mathbf{c}}_{\mathrm{phys},t}\) を出力する．

本研究では，
推定対象の次元を低次元に制限する．
これは，
すべての物理パラメータを同時に高精度で推定することを目的とするのではなく，
制御性能に支配的な要因を切り出すことを重視しているためである．
このような低次元の明示的推定であっても，
後述する計画過程において有効な情報として機能することを示す．


\section{推定に基づく適応的計画}
\label{sec:adaptive_planning}

本節では，
前節で推定した物理パラメータを用いて，
モデル予測制御をどのように適応させるかについて述べる．
提案手法では，
推定結果を世界モデルおよび計画過程に条件として与えることで，
環境変動に応じた将来予測と行動計画を実現する．


\subsection{物理パラメータの正規化と注入方法}
\label{subsec:parameter_injection}

推定された物理パラメータ
\(\hat{\mathbf{c}}_{\mathrm{phys},t}\) は，
世界モデルおよび計画アルゴリズムに入力される前に，
正規化処理を施す．
これは，
学習時に用いたパラメータ分布と
推定値のスケールを整合させるためである．

本研究では，
正規化された物理パラメータを，
潜在状態に直接結合するのではなく，
遷移モデルや報酬モデルの条件として与える．
この設計により，
潜在状態表現そのものを変更することなく，
物理特性の違いを将来予測に反映できる．

このような条件付けは，
物理パラメータが状態とは異なる時間スケールで変化するという仮定と整合的であり，
推定誤差が潜在状態推定に直接影響することを防ぐ効果も持つ．


\subsection{条件付き世界モデルによる将来予測}
\label{subsec:conditional_dynamics}

物理パラメータを条件として導入した場合，
潜在空間における状態遷移は次のように表される．

\begin{align}
\mathbf{s}_{t+1}
=
f(\mathbf{s}_t, \mathbf{a}_t, \hat{\mathbf{c}}_{\mathrm{phys},t}).
\end{align}

この条件付き遷移モデルにより，
同一の潜在状態および行動であっても，
物理パラメータの違いに応じて
異なる将来状態が予測される．
これにより，
世界モデルは
環境ごとのダイナミクス差異を明示的に表現することが可能となる．

条件付き世界モデルを用いたロールアウトでは，
推定された物理パラメータを固定したまま，
複数ステップ先までの潜在状態遷移を予測する．
この予測結果に基づき，
報酬および価値が評価され，
モデル予測制御における行動系列の最適化が行われる．


\subsection{推定パラメータ条件下での MPPI 計画}
\label{subsec:conditional_mppi}

TD-MPC2 では，
モデル予測制御の最適化手法として
Model Predictive Path Integral (MPPI) が用いられている．
提案手法では，
この MPPI による計画過程においても，
推定された物理パラメータを条件として用いる．

具体的には，
各サンプルされた行動系列に対して，
条件付き世界モデルを用いてロールアウトを行い，
推定パラメータに整合した報酬および価値を評価する．
これにより，
計画は
「現在推定されている環境」に最も適した行動系列を選択する．

推定誤差が存在する場合でも，
MPPI によるサンプリングベースの最適化は，
複数の行動候補を並列に評価するため，
局所的な推定誤差に対して比較的頑健である．
この性質により，
提案手法は，
完全な同定が得られない状況においても，
安定した制御性能を維持できる．


\section{学習アルゴリズム}
\label{sec:learning_algorithm}

本節では，
提案手法における学習アルゴリズムについて述べる．
提案手法は，
物理パラメータ推定器と，
条件付き TD-MPC2 コントローラという
異なる役割を持つ二つのモジュールから構成されている．
本研究では，
それぞれの目的および時間スケールの違いを考慮し，
両者を分離して学習する方針を採用する．


\subsection{物理パラメータ推定器の学習}
\label{subsec:estimator_training}

物理パラメータ推定器は，
相互作用履歴 \(\mathcal{H}_t\) を入力として，
環境に固有な物理パラメータ
\(\mathbf{c}_{\mathrm{phys}}\) を出力する回帰モデルとして構成される．
本研究では，
シミュレーション環境において
真の物理パラメータが既知であることを利用し，
推定器を教師あり学習によって訓練する．

具体的には，
履歴 \(\mathcal{H}_t\) と対応する真の物理パラメータ
\(\mathbf{c}_{\mathrm{phys}}\) の組を学習データとし，
次の二乗誤差損失を最小化する．

\begin{align}
\mathcal{L}_{\mathrm{est}}
=
\left\|
\hat{\mathbf{c}}_{\mathrm{phys},t}
-
\mathbf{c}_{\mathrm{phys}}
\right\|^2 .
\end{align}

ここで，
\(\hat{\mathbf{c}}_{\mathrm{phys},t}\) は
推定器による予測値を表す．
物理パラメータは，
エピソード内でほぼ一定であるため，
履歴の任意の時刻において同一の教師信号を用いることができる．
この性質により，
推定器は比較的安定した教師あり学習が可能である．

なお，
本研究では，
推定器を制御器と同時にオンラインで更新することは行わない．
これは，
推定器の学習誤差が
制御器の学習過程に直接影響することを避けるためである．
推定器は，
制御とは独立に学習された後，
制御時には固定されたモジュールとして用いられる．


\subsection{条件付き TD-MPC2 コントローラの学習}
\label{subsec:controller_training}

条件付き TD-MPC2 コントローラは，
推定された物理パラメータを条件として受け取り，
潜在空間上の世界モデルおよび価値関数を学習する．
学習アルゴリズムの基本構造は，
第\ref{chap:preliminary}章で述べた
標準的な TD-MPC2 と同一である．

具体的には，
観測 \(\mathbf{o}_t\) から得られた潜在状態
\(\mathbf{s}_t\) に対して，
条件付き遷移モデル
\(\mathbf{s}_{t+1} = f(\mathbf{s}_t, \mathbf{a}_t, \hat{\mathbf{c}}_{\mathrm{phys},t})\)
を用いた多段階予測を行い，
報酬モデルおよび価値関数を
時間的差分誤差に基づいて更新する．

ここで重要なのは，
物理パラメータは
制御器に対して外部から与えられる条件変数として扱われ，
制御器内部の潜在状態推定や価値学習の構造自体は変更しない点である．
この設計により，
TD-MPC2 が持つ
高い学習安定性およびサンプル効率を維持したまま，
環境ごとの差異を反映した制御が可能となる．


\subsection{勾配分離による学習安定化}
\label{subsec:gradient_decoupling}

提案手法では，
物理パラメータ推定器と
条件付き TD-MPC2 コントローラの間で，
勾配を明示的に分離する．
具体的には，
推定器の出力
\(\hat{\mathbf{c}}_{\mathrm{phys},t}\) を
制御器に入力する際に，
勾配を遮断する処理を行う．

この勾配分離により，
制御性能に基づく誤差が
推定器の学習に逆伝播することを防ぐ．
もし両者を完全に joint learning した場合，
制御器側の不安定な学習信号が
推定器の出力を歪め，
結果として推定と制御の双方が不安定化する可能性がある．

提案手法では，
推定器は
「物理パラメータを推定する」という明確な目的のもとで学習され，
制御器は
「推定された条件下で最適な行動を選択する」
という役割に専念する．
この役割分担に基づく学習分離により，
全体として安定した学習および制御性能が得られると考えられる．
