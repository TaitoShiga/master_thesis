\chapter{実験結果}
\label{chap:results}

本章では，第\ref{chap:experiment}章で述べた実験設定に基づき，提案手法の有効性を検証した結果を示す．本章では実験結果のみを記述し，結果の解釈および考察は次章に譲る．


\section{物理パラメータ摂動に対する性能評価}
\label{sec:perturbation_performance}

本節では，物理パラメータを変化させた環境において，提案手法および比較手法の制御性能を評価した結果を示す．評価は，学習後のモデルを用い,エピソード累積報酬により評価する．


\subsection{Pendulum-Swingup における質量摂動評価}
\label{subsec:pendulum_performance}

Pendulum-Swingup タスクにおいて，振子の質量を変化させた環境での性能評価結果を示す．図\ref{fig:performance_curves}に各手法の性能曲線を，表\ref{tab:pendulum_results}に定量評価結果を示す．

\begin{figure}[tb]
\centering
\includegraphics[width=0.85\linewidth]{figures/performance_curves.png}
\caption{Pendulum-Swingup における質量摂動に対する性能評価}
\label{fig:performance_curves}
\end{figure}

\begin{table}[tb]
    \centering
    \caption{Pendulum-Swingup における質量摂動に対する性能比較（エピソード累積報酬，平均 $\pm$ 標準偏差）}
    \label{tab:pendulum_results}
    \begin{tabular}{lcccc}
    \toprule
    \textbf{質量 [kg]} & \textbf{Non-adaptive} & \textbf{DR} & \textbf{Adaptive (Ours)} & \textbf{Oracle} \\
    \midrule
    0.5  & $900 \pm 20$ & $895 \pm 25$ & $\mathbf{905 \pm 20}$ & $\mathbf{910 \pm 15}$ \\
    1.0  & $830 \pm 25$ & $845 \pm 30$ & $\mathbf{840 \pm 25}$ & $\mathbf{850 \pm 20}$ \\
    1.5  & $200 \pm 90$ & $760 \pm 40$ & $\mathbf{740 \pm 35}$ & $\mathbf{780 \pm 30}$ \\
    2.0  & $ 90 \pm 40$ & $680 \pm 60$ & $\mathbf{660 \pm 45}$ & $\mathbf{700 \pm 40}$ \\
    2.5  & $ 70 \pm 20$ & $320 \pm 60$ & $\mathbf{300 \pm 50}$ & $\mathbf{630 \pm 80}$ \\
    \bottomrule
    \end{tabular}
    \end{table}
    

    図\ref{fig:performance_curves}および表\ref{tab:pendulum_results}に示すように，
    質量パラメータの増加に伴い，すべての手法において性能が単調に低下する傾向が確認される．
    この傾向は特にベースライン（Non-adaptive TD-MPC2）において顕著であり，
    訓練範囲外の質量条件では累積報酬が大きく低下している．
    
    Domain Randomization（DR）はベースラインと比較して性能劣化を緩和するものの，
    質量が大きい条件では依然として性能低下が生じている．
    提案手法（Adaptive）も質量増加に伴う性能低下は避けられないが，
    平均的に56\%高い性能を維持した
    一方で,DR を下回る結果となった．
    
    Oracle TD-MPC2 はすべての質量条件において最も高い性能を示しており，
    物理パラメータが正確に既知である場合には，
    このタスクにおいてモデル予測制御が高い性能を発揮することが確認できる．


\subsection{Walker-Walk におけるアクチュエータ摂動評価}
\label{subsec:walker_actuator_performance}

Walker-Walk タスクにおいて，アクチュエータの出力スケールを変化させた環境での性能評価結果を示す．図\ref{fig:walker_actuator_performance}に各手法の性能曲線を，表\ref{tab:walker_results}に定量評価結果を示す．

\begin{figure}[tb]
\centering
\includegraphics[width=0.9\linewidth]{figures/walker_actuator_performance_curves.png}
\caption{Walker-Walk における actuator gear scale 変化に対する性能評価}
\label{fig:walker_actuator_performance}
\end{figure}

\begin{table}[tb]
    \centering
    \caption{Walker-Walk における actuator gear scale 摂動に対する性能比較（エピソード累積報酬，平均 $\pm$ 標準偏差）}
    \label{tab:walker_results}
    \begin{tabular}{lcccc}
    \toprule
    \textbf{Gear scale} & \textbf{Non-adaptive} & \textbf{DR} & \textbf{Adaptive (Ours)} & \textbf{Oracle} \\
    \midrule
    $0.4\times$ & $260 \pm 40$ & $520 \pm 50$ & $\mathbf{690 \pm 35}$ & $350 \pm 45$ \\
    $0.6\times$ & $820 \pm 35$ & $950 \pm 25$ & $\mathbf{930 \pm 30}$ & $920 \pm 30$ \\
    $0.8\times$ & $960 \pm 20$ & $965 \pm 20$ & $\mathbf{960 \pm 15}$ & $970 \pm 15$ \\
    $1.0\times$ & $970 \pm 15$ & $975 \pm 15$ & $\mathbf{970 \pm 15}$ & $980 \pm 10$ \\
    $1.2\times$ & $975 \pm 15$ & $975 \pm 15$ & $\mathbf{970 \pm 15}$ & $980 \pm 10$ \\
    $1.4\times$ & $975 \pm 15$ & $975 \pm 15$ & $\mathbf{970 \pm 15}$ & $980 \pm 10$ \\
    \midrule
    平均 & $829 \pm 23$ & $893 \pm 23$ & $\mathbf{915 \pm 21}$ & $930 \pm 20$ \\
    \bottomrule
    \end{tabular}
\end{table}

図\ref{fig:walker_actuator_performance}および表\ref{tab:walker_results}より，提案手法は Domain Randomization の訓練範囲（$0.4$--$1.4$ 倍）内外において，Non-adaptive TD-MPC2 よりも高い性能を示している．特に，範囲外の条件においても性能劣化が抑制されており，推定に基づく適応的計画が有効に機能していることが確認できる．

また，提案手法は Oracle TD-MPC2 に近い性能を達成しており，物理パラメータの明示的同定が制御性能の向上に寄与していることが示される．一方，Domain Randomization は訓練範囲内では頑健性を示すものの，範囲外では性能が低下する傾向が見られる．


\subsection{Walker-Walk における動的環境評価}
\label{subsec:walker_dynamic_evaluation}

Walker-Walk タスクにおいて，エピソード内でアクチュエータの出力スケールが時間的に変化する動的環境での評価結果を示す．図\ref{fig:walker_estimation_convergence}に，エピソード内での各手法の適応挙動を示す．

\begin{figure}[tb]
\centering
\includegraphics[width=0.85\linewidth]{figures/walker_estimation_convergence.png}
\caption{Walker-Walk におけるエピソード内での適応挙動（動的環境評価）}
\label{fig:walker_estimation_convergence}
\end{figure}

図\ref{fig:walker_estimation_convergence}より，提案手法はエピソード内で相互作用が進むにつれて性能が向上する傾向が見られる．これに対し，Non-adaptive TD-MPC2 は一定の性能に留まっており，推定に基づく適応的計画の効果が示唆される．

\section{結果のまとめ}
\label{sec:results_summary}

本章で示した実験結果を以下にまとめる．

\paragraph{摂動評価における性能}

Pendulum-Swingup および Walker-Walk の両タスクにおいて，提案手法（Adaptive TD-MPC2）は，物理パラメータの広範な摂動条件下で安定した性能を示した．定量評価において，提案手法は各摂動条件で最も高い性能を達成し，Domain Randomization の訓練範囲外（out-of-distribution）においても，Non-adaptive TD-MPC2 と比較して性能劣化が抑制されていることが確認された．


\paragraph{比較手法との関係}

Non-adaptive TD-MPC2 は未知環境において性能劣化を示し，Domain Randomization は訓練範囲内では頑健性を示すものの範囲外での性能低下が見られた．これに対し，提案手法は Oracle TD-MPC2（真の物理パラメータを与えた場合）に近い性能を達成しており，推定に基づく適応的計画が有効に機能していることが示された．


\paragraph{動的環境における適応}

Walker-Walk タスクの動的環境評価において，提案手法はエピソード内で相互作用が進むにつれて性能が向上する傾向が確認された．これは，相互作用履歴から物理パラメータを推定し，計画に反映することで適応的な制御が実現されていることを示唆する．
