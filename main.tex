\documentclass[shuuron]{kuee} % ←ここが修士化の本丸

% ===== packages =====
\usepackage{booktabs}
\usepackage{amsmath, amssymb, amsfonts}
\usepackage{mathtools}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage[dvipdfmx]{graphicx}
\usepackage{url}
\usepackage{multirow}

% 図の探索パス（必要なら）
\graphicspath{{figures/}}

\DeclareMathOperator*{\argmax}{arg\,max}

% ===== cover info =====
\title{不確実環境における\\適応的モデルベース強化学習法}
\etitle{Adaptive Model-Based Reinforcement Learning in Uncertain Environments}
\author{志賀 泰斗}
\eauthor{Taito Shiga}
\professor{石井 信 教授}
% course/department は cls 側で修士用が既定値に切り替わりますが、
% 表示を上書きしたいなら \course{...} \department{...} を書けます。:contentReference[oaicite:3]{index=3}
\date{令和8年1月提出}

\begin{document}
\maketitle

\begin{eabstract}
% English abstract here
モデルベース強化学習は，環境の遷移ダイナミクスを学習し，
その予測に基づいて行動を計画することで高いサンプル効率を実現する．
しかし，学習時に想定された物理パラメータから実行時の環境が乖離した場合，
世界モデルの予測精度が低下し，計画の信頼性が損なわれるという課題がある．
本研究では，物理パラメータが未知であり,エピソード内で一定または変動する環境において，
過去の相互作用履歴から環境特性を明示的に推定し，
その推定結果を世界モデルおよび計画過程に条件として与えることで，
環境変動下でも整合的な将来予測を実現する適応的制御手法を提案する．
まず，真の物理パラメータを与えた Oracle 条件での検証により，
物理パラメータの明示的な情報が計画の信頼性向上に寄与することを確認し，
提案手法のアプローチの妥当性を示した．
その上で，Pendulum-Swingup および Walker-Walk タスクを用いた実験により，
提案手法が高次元タスクにおいて既存手法を上回る性能を達成し，
動的環境においても環境変化に追従できることを実証した．
\end{eabstract}

\tableofcontents

% ===== chapters =====
\input{chapters/chapter1}
\input{chapters/chapter2}
\input{chapters/chapter3}
\input{chapters/chapter4}
\input{chapters/chapter5}
\input{chapters/chapter6}
\input{chapters/chapter7}
\input{chapters/chapter8}

\begin{acknowledgements}
% 謝辞
本研究を進めるに際して, 指導教員の石井信教授, 国
際電気通信基礎技術研究所 (ATR) の久保顕大さんから多くの助言, 指導を頂きま
した. 厚く感謝を申し上げます. また, 研究の準備および議論を通じて協力して頂
いた石井研究室の皆様にも感謝申し上げます.
\end{acknowledgements}

\clearpage
\input{chapters/appendix}


% ===== bibliography =====
% 1) bst を refs/ に置く場合
\bibliographystyle{refs/kueethesis}
% 2) bib を refs/ に置く場合（例：refs/main.bib）

\bibliography{refs/main}

\end{document}
